{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vasiliki Konstantopoulou\n",
    "###### Deep Learning\n",
    "##### Assignment 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.stats.mstats import zscore\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.optimizers import Adagrad\n",
    "from keras.optimizers import Adamax\n",
    "from keras.optimizers import Nadam\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = [10, 100, 1000, 10000]\n",
    "num_classes = 10\n",
    "epochs = [10, 50, 100]\n",
    "learning = [0.01, 0.1, 0.001, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Dataset and split in train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train, trainLabels), (test, testLabels) = cifar10.load_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.astype('float32')\n",
    "test = test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_255norm = train / 255  #MaxValue normalisation\n",
    "test_255norm = test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_min = train.min(axis=(1, 2), keepdims=True)  #MinMax normilisation\n",
    "train_max = train.max(axis=(1, 2), keepdims=True)\n",
    "test_min = test.min(axis=(1, 2), keepdims=True)\n",
    "test_max = test.max(axis=(1, 2), keepdims=True)\n",
    "train_minmax = (train - train_min)/(train_max-train_min)\n",
    "test_minmax = (test - test_min)/(test_max-test_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tain_zscore = zscore(train)  #z-score normalisation\n",
    "test_zscore = zscore(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLabels = keras.utils.to_categorical(trainLabels, num_classes)\n",
    "testLabels = keras.utils.to_categorical(testLabels, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment with different normalisation methods with Adam and SGD Optimisers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Flatten(input_shape=(32, 32, 3)))\n",
    "model1.add(Dense(30, activation='relu'))\n",
    "model1.add(Dense(20, activation='sigmoid'))\n",
    "model1.add(Dense(num_classes, activation='softmax'))\n",
    "model1.summary()\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "optimizer= SGD(), #keras.optimizers.Adam(),                         #to reproduce uncomment the right optimiser\n",
    "metrics=['accuracy'])\n",
    "model1.fit(train, trainLabels, epochs = 10, validation_data=(test, testLabels))\n",
    "score = model1.evaluate(test, testLabels, verbose=0)\n",
    "print('loss:', score[0])\n",
    "print('Accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Flatten(input_shape=(32, 32, 3)))\n",
    "model2.add(Dense(30, activation='relu'))\n",
    "model2.add(Dense(20, activation='sigmoid'))\n",
    "model2.add(Dense(num_classes, activation='softmax'))\n",
    "model2.summary()\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "optimizer=SGD(), #keras.optimizers.Adam(),\n",
    "metrics=['accuracy'])\n",
    "model2.fit(train_255norm, trainLabels, epochs = 10, validation_data=(test_255norm, testLabels))\n",
    "score = model2.evaluate(test_255norm, testLabels, verbose=0)\n",
    "print('loss:', score[0])\n",
    "print('Accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Flatten(input_shape=(32, 32, 3)))\n",
    "model3.add(Dense(30, activation='relu'))\n",
    "model3.add(Dense(20, activation='sigmoid'))\n",
    "model3.add(Dense(num_classes, activation='softmax'))\n",
    "model3.summary()\n",
    "model3.compile(loss='categorical_crossentropy',\n",
    "optimizer= SGD(), #keras.optimizers.Adam(),\n",
    "metrics=['accuracy'])\n",
    "model3.fit(train_minmax, trainLabels, epochs = 10, validation_data=(test_minmax, testLabels))\n",
    "score = model3.evaluate(test_minmax, testLabels, verbose=0)\n",
    "print('loss:', score[0])\n",
    "print('Accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Flatten(input_shape=(32, 32, 3)))\n",
    "model4.add(Dense(30, activation='relu'))\n",
    "model4.add(Dense(20, activation='sigmoid'))\n",
    "model4.add(Dense(num_classes, activation='softmax'))\n",
    "model4.summary()\n",
    "model4.compile(loss='categorical_crossentropy',\n",
    "optimizer= SGD(), #keras.optimizers.Adam(),\n",
    "metrics=['accuracy'])\n",
    "model4.fit(tain_zscore, trainLabels, epochs = 10, validation_data=(test_zscore, testLabels))\n",
    "score = model4.evaluate(test_zscore, testLabels, verbose=0)\n",
    "print('loss:', score[0])\n",
    "print('Accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment with various optimisers and z-score normalised dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model5 = Sequential()\n",
    "model5.add(Flatten(input_shape=(32, 32, 3)))\n",
    "model5.add(Dense(30, activation='relu'))\n",
    "model5.add(Dense(20, activation='sigmoid'))\n",
    "model5.add(Dense(num_classes, activation='softmax'))\n",
    "model5.summary()\n",
    "model5.compile(loss='categorical_crossentropy',\n",
    "optimizer=RMSprop(),\n",
    "metrics=['accuracy'])\n",
    "model5.fit(tain_zscore, trainLabels, epochs = 10, validation_data=(test_zscore, testLabels))\n",
    "score = model5.evaluate(test_zscore, testLabels, verbose=0)\n",
    "print('loss:', score[0])\n",
    "print('Accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = Sequential()\n",
    "model6.add(Flatten(input_shape=(32, 32, 3)))\n",
    "model6.add(Dense(30, activation='relu'))\n",
    "model6.add(Dense(20, activation='sigmoid'))\n",
    "model6.add(Dense(num_classes, activation='softmax'))\n",
    "model6.summary()\n",
    "model6.compile(loss='categorical_crossentropy',\n",
    "optimizer=  tf.train.AdamOptimizer(), #Adagrad(), #Nadam(), #Adadelta(),      #to reproduce uncomment the chosen optimiser\n",
    "metrics=['accuracy'])\n",
    "model6.fit(tain_zscore, trainLabels, epochs = 10, validation_data=(test_zscore, testLabels))\n",
    "score = model6.evaluate(test_zscore, testLabels, verbose=0)\n",
    "print('loss:', score[0])\n",
    "print('Accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model7 = Sequential()\n",
    "model7.add(Flatten(input_shape=(32, 32, 3)))\n",
    "model7.add(Dense(30, activation='relu'))\n",
    "model7.add(Dense(20, activation='sigmoid'))\n",
    "model7.add(Dense(num_classes, activation='softmax'))\n",
    "model7.summary()\n",
    "model7.compile(loss='categorical_crossentropy',\n",
    "optimizer=SGD(),\n",
    "metrics=['accuracy'])\n",
    "model7.fit(tain_zscore, trainLabels, epochs = 10, validation_data=(test_zscore, testLabels))\n",
    "score = model7.evaluate(test_zscore, testLabels, verbose=0)\n",
    "print('loss:', score[0])\n",
    "print('Accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameters tuning using Adam and SGD optimisers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in learning: #bach_size, learning    #to reproduce uncomment the chosen hyper parameter\n",
    "    model8 = Sequential()\n",
    "    model8.add(Flatten(input_shape=(32, 32, 3)))\n",
    "    model8.add(Dense(30, activation='relu'))\n",
    "    model8.add(Dense(20, activation='sigmoid'))\n",
    "    model8.add(Dense(num_classes, activation='softmax'))\n",
    "    model8.summary()\n",
    "    model8.compile(loss='categorical_crossentropy',\n",
    "    optimizer=SGD(lr= i),\n",
    "    metrics=['accuracy'])\n",
    "    model8.fit(tain_zscore, trainLabels, epochs = 50, batch_size = 10, validation_data=(test_zscore, testLabels))\n",
    "    score = model8.evaluate(test_zscore, testLabels, verbose=0)\n",
    "    print('loss:', score[0])\n",
    "    print('Accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in learning:  #batch_size, #epochs    #to reproduce uncomment the chosen hyper parameter\n",
    "    model9 = Sequential()\n",
    "    model9.add(Flatten(input_shape=(32, 32, 3)))\n",
    "    model9.add(Dense(30, activation='relu'))\n",
    "    model9.add(Dense(20, activation='sigmoid'))\n",
    "    model9.add(Dense(num_classes, activation='softmax'))\n",
    "    model9.summary()\n",
    "    model9.compile(loss='categorical_crossentropy',\n",
    "    optimizer=keras.optimizers.Adam(lr = i), \n",
    "    metrics=['accuracy'])\n",
    "    model9.fit(tain_zscore, trainLabels, epochs = 50, batch_size = 100, validation_data=(test_zscore, testLabels))\n",
    "    score = model9.evaluate(test_zscore, testLabels, verbose=0)\n",
    "    print('loss:', score[0])\n",
    "    print('Accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment with width and depth of neural netwrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model10.add(Flatten(input_shape=(32, 32, 3)))\n",
    "model10.add(Dense(500, activation='relu'))      \n",
    "model10.add(Dense(400, activation='relu'))  \n",
    "model10.add(Dense(num_classes, activation='softmax'))\n",
    "model10.summary()\n",
    "model10.compile(loss='categorical_crossentropy',\n",
    "optimizer=keras.optimizers.Adam(), #SGD(),\n",
    "metrics=['accuracy'])\n",
    "model10.fit(tain_zscore, trainLabels, epochs = 50, batch_size = 10, validation_data=(test_zscore, testLabels))\n",
    "score = model10.evaluate(test_zscore, testLabels, verbose=0)\n",
    "print('loss:', score[0])\n",
    "print('Accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model11 = Sequential()\n",
    "model11.add(Flatten(input_shape=(32, 32, 3)))\n",
    "model11.add(Dense(512, activation='relu'))      \n",
    "model11.add(Dense(128, activation='relu'))   \n",
    "model11.add(Dense(num_classes, activation='softmax'))\n",
    "model11.summary()\n",
    "model11.compile(loss='categorical_crossentropy',\n",
    "optimizer=keras.optimizers.Adam(), #SGD(),\n",
    "metrics=['accuracy'])\n",
    "model11.fit(tain_zscore, trainLabels, epochs = 50, batch_size = 10, validation_data=(test_zscore, testLabels))\n",
    "score = model11.evaluate(test_zscore, testLabels, verbose=0)\n",
    "print('loss:', score[0])\n",
    "print('Accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model12 = Sequential()\n",
    "model12.add(Flatten(input_shape=(32, 32, 3)))\n",
    "model12.add(Dense(512, activation='relu'))\n",
    "model12.add(Dropout(0.25))\n",
    "model12.add(Dense(128, activation='relu'))\n",
    "model12.add(Dense(num_classes, activation='softmax'))\n",
    "model12.summary()\n",
    "model12.compile(loss='categorical_crossentropy',\n",
    "optimizer=SGD(),  \n",
    "metrics=['accuracy'])\n",
    "history = model12.fit(tain_zscore, trainLabels, epochs = 10, batch_size = 10, validation_data=(test_zscore, testLabels))\n",
    "score = model12.evaluate(test_zscore, testLabels, verbose=0)\n",
    "print('loss:', score[0])\n",
    "print('Accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model13 = Sequential()\n",
    "model13.add(Flatten(input_shape=(32, 32, 3)))\n",
    "model13.add(Dense(512, activation='relu'))      \n",
    "model13.add(Dense(256, activation='relu'))   \n",
    "model13.add(Dense(128, activation='relu'))\n",
    "model13.add(Dense(64, activation='relu'))\n",
    "model13.add(Dense(32, activation='relu'))\n",
    "model13.add(Dense(num_classes, activation='softmax'))\n",
    "model13.summary()\n",
    "model13.compile(loss='categorical_crossentropy',\n",
    "optimizer=  SGD(),\n",
    "metrics=['accuracy'])\n",
    "model13.fit(tain_zscore, trainLabels, epochs = 50, batch_size = 10, validation_data=(test_zscore, testLabels), callbacks=[EarlyStopping(patience=5, monitor = 'val_acc')])\n",
    "score = model13.evaluate(test_zscore, testLabels, verbose=0)\n",
    "print('loss:', score[0])\n",
    "print('Accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try different loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model14 = Sequential()\n",
    "model14.add(Flatten(input_shape=(32, 32, 3)))\n",
    "model14.add(Dense(512, activation='relu'))\n",
    "model14.add(Dense(128, activation='relu'))\n",
    "model14.add(Dense(num_classes, activation='softmax'))\n",
    "model14.summary()\n",
    "model14.compile(loss='categorical_crossentropy',\n",
    "optimizer=SGD(),  \n",
    "metrics=['accuracy'])\n",
    "history = model14.fit(tain_zscore, trainLabels, epochs = 40, batch_size = 10, validation_data=(test_zscore, testLabels), callbacks = [ReduceLROnPlateau(monitor = 'val_loss', patience = 5, verbose = min)])\n",
    "score = model14.evaluate(test_zscore, testLabels, verbose=0)\n",
    "print('loss:', score[0])\n",
    "print('Accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history1.history['acc'])\n",
    "plt.plot(history1.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history1.history['acc'])\n",
    "plt.plot(history1.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model15 = Sequential()\n",
    "model15.add(Flatten(input_shape=(32, 32, 3)))\n",
    "model15.add(Dense(512, activation='relu'))\n",
    "model15.add(Dense(128, activation='relu'))\n",
    "model15.add(Dense(num_classes, activation='softmax'))\n",
    "model15.summary()\n",
    "model15.compile(loss='categorical_hinge',  #mean_squared_error\n",
    "optimizer=SGD(),  \n",
    "metrics=['accuracy'])\n",
    "history = model15.fit(tain_zscore, trainLabels, epochs = 40, batch_size = 10, validation_data=(test_zscore, testLabels), callbacks = [ReduceLROnPlateau()])\n",
    "score = model15.evaluate(test_zscore, testLabels, verbose=0)\n",
    "print('loss:', score[0])\n",
    "print('Accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdgen = ImageDataGenerator(\n",
    "    featurewise_center = False,  \n",
    "    samplewise_center = False,  \n",
    "    featurewise_std_normalization = False,  \n",
    "    samplewise_std_normalization = False,  \n",
    "    zca_whitening = False,  \n",
    "    rotation_range = 10,  \n",
    "    width_shift_range = 0.1,  \n",
    "    height_shift_range = 0.1,  \n",
    "    horizontal_flip = True,  \n",
    "    vertical_flip = False,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdgen.fit(tain_zscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgen = imdgen.flow(tain_zscore, trainLabels, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model16 = Sequential()\n",
    "model16.add(Flatten(input_shape=(32, 32, 3)))\n",
    "model16.add(Dense(512, activation='relu'))\n",
    "model16.add(Dense(128, activation='relu'))\n",
    "model16.add(Dense(num_classes, activation='softmax'))\n",
    "model16.summary()\n",
    "model16.compile(loss='categorical_hinge',\n",
    "optimizer=SGD(),  \n",
    "metrics=['accuracy']) \n",
    "model16.fit_generator(dgen, samples_per_epoch=tain_zscore.shape[0], nb_epoch=4, validation_data=(test_zscore, testLabels), callbacks=[EarlyStopping(patience = 5)], verbose=0)  \n",
    "score = model16.evaluate(test_zscore, testLabels, verbose=0)\n",
    "print('loss:', score[0])\n",
    "print('Accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
